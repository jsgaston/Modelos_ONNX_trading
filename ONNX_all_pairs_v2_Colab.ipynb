# Montar Drive
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# Instalar solo lo necesario (TensorFlow 2.19 ya incluye Keras)
!pip install numpy==1.26.4  tf-keras==2.19.0 tf2onnx protobuf==3.20.3 scikit-learn pandas

print("\n‚úÖ Librer√≠as instaladas!")
print("‚ö†Ô∏è IMPORTANTE: Ve a Runtime > Restart runtime")
print("‚ö†Ô∏è Despu√©s ejecuta la siguiente celda (el script de entrenamiento)")







# ===================================================================
# SCRIPT DE ENTRENAMIENTO DE MODELOS FOREX
# Ejecutar DESPU√âS de instalar librer√≠as y reiniciar runtime
# ===================================================================
!pip install numpy==1.26.4 
# ===================================================================
# MONTAR GOOGLE DRIVE
# ===================================================================
print("Montando Google Drive...")
from google.colab import drive
drive.mount('/content/drive', force_remount=True)
print("‚úì Google Drive montado correctamente\n")

# ===================================================================
# IMPORTAR LIBRER√çAS
# ===================================================================
import tensorflow as tf
import numpy as np
import pandas as pd
import os 
import sys
import shutil
import subprocess
from datetime import timedelta, datetime
from sklearn.preprocessing import MinMaxScaler
import tf2onnx

# Importar Keras
from keras.models import Sequential
from keras.layers import Dense, Conv1D, MaxPooling1D, Dropout, LSTM
from keras.metrics import RootMeanSquaredError as rmse
from keras.callbacks import EarlyStopping

print("‚úì Librer√≠as importadas correctamente")
print(f"TensorFlow version: {tf.__version__}")
print(f"tf2onnx version: {tf2onnx.__version__}\n")

# ===================================================================
# CONFIGURACI√ìN DE RUTAS - AJUSTA ESTAS SEG√öN TU ESTRUCTURA
# ===================================================================
DATA_PATH = '/content/drive/MyDrive/forex_data/'  # Ruta donde est√°n los CSVs
MODEL_PATH = '/content/drive/MyDrive/forex_models/'  # Ruta donde se guardar√°n los ONNX

# Crear carpeta de modelos si no existe
os.makedirs(MODEL_PATH, exist_ok=True)

print(f"üìÇ Data path (CSVs): {DATA_PATH}")
print(f"üíæ Model path (ONNX): {MODEL_PATH}\n")

# ===================================================================
# PAR√ÅMETROS DE ENTRENAMIENTO
# ===================================================================
symbols = ["USDCAD", "EURUSD", "GBPUSD", "USDCHF", "AUDUSD"]
inp_history_size = 120
DAYS_TO_USE = 120  # √öltimos 120 d√≠as de datos

# ===================================================================
# FUNCIONES
# ===================================================================

def split_sequence(sequence, n_steps):
    """Split a univariate sequence into samples"""
    X, y = list(), list()
    for i in range(len(sequence)):
       end_ix = i + n_steps
       if end_ix > len(sequence)-1:
          break
       seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]
       X.append(seq_x)
       y.append(seq_y)
    return np.array(X), np.array(y)

def train_and_save_model(simbol, end_date, model_suffix=""):
    """
    Trains a model for a given symbol and time period.
    
    Parameters:
    - simbol: Trading symbol (e.g., "EURUSD")
    - end_date: End date for the training data
    - model_suffix: Suffix to add to model name (e.g., "backtesting")
    """
    # Calculate start date based on end date (√∫ltimos 120 d√≠as)
    start_date = end_date - timedelta(days=DAYS_TO_USE)
    
    # Create model name with optional suffix
    if model_suffix:
        inp_model_name = f"model.{simbol}.H1.120.{model_suffix}.onnx"
    else:
        inp_model_name = f"model.{simbol}.H1.120.onnx"
    
    print(f"\n{'='*60}")
    print(f"Procesando {simbol} - {model_suffix if model_suffix else 'Trading'}")
    print(f"Per√≠odo: {start_date.strftime('%Y-%m-%d')} hasta {end_date.strftime('%Y-%m-%d')}")
    print(f"Usando √∫ltimos {DAYS_TO_USE} d√≠as de datos")
    print(f"{'='*60}\n")
    
    try:
        # Leer datos desde CSV en Drive
        csv_file = f"{DATA_PATH}{simbol}_H1.csv"
        
        if not os.path.exists(csv_file):
            print(f"‚ùå ERROR: No se encontr√≥ el archivo {csv_file}")
            return False
        
        # Leer CSV con separador de tabulaci√≥n
        df = pd.read_csv(csv_file, sep='\t')
        print(f"üìä Total registros en CSV: {len(df)}")
        
        # Convertir columna DATE y TIME a datetime
        df['datetime'] = pd.to_datetime(df['<DATE>'] + ' ' + df['<TIME>'], format='%Y.%m.%d %H:%M:%S')
        
        # Filtrar por rango de fechas (√∫ltimos 120 d√≠as desde end_date)
        df = df[(df['datetime'] >= start_date) & (df['datetime'] <= end_date)]
        
        if len(df) == 0:
            print(f"‚ùå ERROR: No hay datos en el rango de fechas para {simbol}")
            return False
        
        print(f"‚úì Datos filtrados: {len(df)} registros")
        print(f"  Rango real: {df['datetime'].min()} a {df['datetime'].max()}")
        
        # get close prices only
        data = df[['<CLOSE>']].values
        
        # scale data
        scaler = MinMaxScaler(feature_range=(0,1))
        scaled_data = scaler.fit_transform(data)
        
        # training size is 80% of the data
        training_size = int(len(scaled_data)*0.80) 
        print(f"‚úì Training_size: {training_size}")
        train_data_initial = scaled_data[0:training_size,:]
        test_data_initial = scaled_data[training_size:,:1]
        
        # split into samples
        time_step = inp_history_size
        x_train, y_train = split_sequence(train_data_initial, time_step)
        x_test, y_test = split_sequence(test_data_initial, time_step)
        
        # reshape input to be [samples, time steps, features] which is required for LSTM
        x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)
        x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)
        
        print(f"‚úì x_train shape: {x_train.shape}")
        print(f"‚úì x_test shape: {x_test.shape}")
        
        # define model
        model = Sequential()
        model.add(Conv1D(filters=256, kernel_size=2, activation='relu', padding='same', input_shape=(inp_history_size,1)))
        model.add(MaxPooling1D(pool_size=2))
        model.add(LSTM(100, return_sequences=True))
        model.add(Dropout(0.3))
        model.add(LSTM(100, return_sequences=False))
        model.add(Dropout(0.3))
        model.add(Dense(units=1, activation='sigmoid'))
        model.compile(optimizer='adam', loss='mse', metrics=[rmse()])
        
        print("‚úì Modelo definido")
        
        # Configurar Early Stopping
        early_stop = EarlyStopping(
            monitor='val_loss',
            patience=20,
            restore_best_weights=True,
            verbose=1
        )
        
        # model training con early stopping
        print(f"\nüöÄ Entrenando modelo para {simbol} ({model_suffix if model_suffix else 'Trading'})...")
        history = model.fit(
            x_train, y_train, 
            epochs=3, 
            validation_data=(x_test, y_test), 
            batch_size=32, 
            callbacks=[early_stop],
            verbose=1
        )
        
        # evaluate training data
        train_loss, train_rmse = model.evaluate(x_train, y_train, batch_size=32, verbose=0)
        print(f"\nüìà train_loss={train_loss:.3f}")
        print(f"üìà train_rmse={train_rmse:.3f}")
        
        # evaluate testing data
        test_loss, test_rmse = model.evaluate(x_test, y_test, batch_size=32, verbose=0)
        print(f"üìâ test_loss={test_loss:.3f}")
        print(f"üìâ test_rmse={test_rmse:.3f}")
        
        # First export as TensorFlow SavedModel
        temp_model_path = f"/tmp/temp_model_{simbol}_{model_suffix if model_suffix else 'trading'}"
        
        # Remove temp directory if exists
        if os.path.exists(temp_model_path):
            shutil.rmtree(temp_model_path)
        
        # Export model
        print(f"\nüíæ Exportando modelo temporal...")
        model.export(temp_model_path)
        
        # Convert to ONNX using command line tool
        output_path = MODEL_PATH + inp_model_name
        print(f"üîÑ Convirtiendo a ONNX...")
        cmd = [sys.executable, '-m', 'tf2onnx.convert', '--saved-model', temp_model_path, '--output', output_path, '--opset', '13']
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            print(f"‚úÖ Modelo guardado en: {output_path}")
        else:
            print(f"‚ùå Error guardando modelo:")
            print(result.stderr)
            return False
        
        # Clean up temp directory
        if os.path.exists(temp_model_path):
            shutil.rmtree(temp_model_path)
        
        print(f"\n‚úÖ {simbol} - {model_suffix if model_suffix else 'Trading'} completado exitosamente!\n")
        return True
        
    except Exception as e:
        print(f"\n‚ùå ERROR procesando {simbol} - {model_suffix if model_suffix else 'Trading'}: {str(e)}\n")
        import traceback
        traceback.print_exc()
        return False

# ===================================================================
# PROCESO PRINCIPAL
# ===================================================================

print(f"\n{'#'*60}")
print("# üöÄ INICIANDO ENTRENAMIENTO DE MODELOS")
print(f"# üìÖ √öltimos {DAYS_TO_USE} d√≠as de datos por modelo")
print(f"{'#'*60}\n")

# Procesar cada s√≠mbolo con dos modelos
for simbol in symbols:
    print(f"\n{'#'*60}")
    print(f"# INICIANDO PROCESAMIENTO DE {simbol}")
    print(f"{'#'*60}\n")
    
    # Modelo 1: Trading (√∫ltimos 120 d√≠as desde hoy)
    end_date_trading = datetime.now()
    success_trading = train_and_save_model(simbol, end_date_trading, model_suffix="")
    
    # Modelo 2: Backtesting (√∫ltimos 120 d√≠as desde hace 7 d√≠as)
    end_date_backtesting = datetime.now() - timedelta(days=7)
    success_backtesting = train_and_save_model(simbol, end_date_backtesting, model_suffix="backtesting")
    
    if success_trading and success_backtesting:
        print(f"\n{'='*60}")
        print(f"‚úÖ‚úÖ AMBOS MODELOS PARA {simbol} COMPLETADOS EXITOSAMENTE")
        print(f"{'='*60}\n")
    else:
        print(f"\n{'='*60}")
        print(f"‚ö†Ô∏è ALGUNOS MODELOS PARA {simbol} FALLARON")
        print(f"{'='*60}\n")

print(f"\n{'#'*60}")
print("# ‚úÖ PROCESO COMPLETADO PARA TODOS LOS S√çMBOLOS")
print(f"{'#'*60}")
print(f"\nüìÅ Modelos guardados en: {MODEL_PATH}")
print("\nüéâ ¬°Entrenamiento finalizado!")





