# ============================================================================
# LSTM Forex Model Training - Google Colab Version
# ============================================================================

# 1. INSTALACIÓN DE LIBRERÍAS
print("Instalando librerías necesarias...")
# Primero instalar NumPy compatible con tf2onnx
!pip install -q "numpy<2.0"
# Luego el resto de las librerías
!pip install -q tensorflow pandas scikit-learn tf2onnx onnx

# 2. MONTAR GOOGLE DRIVE
from google.colab import drive
drive.mount('/content/drive')

# 3. IMPORTAR LIBRERÍAS
import tensorflow as tf
import numpy as np
import pandas as pd
import tf2onnx
import os
import shutil
import subprocess
from datetime import timedelta, datetime
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, Activation, Conv1D, MaxPooling1D, Dropout, Flatten, LSTM
from keras.metrics import RootMeanSquaredError as rmse
from keras.callbacks import EarlyStopping

# ============================================================================
# 4. CONFIGURACIÓN
# ============================================================================

# Ruta donde se guardarán los modelos en Google Drive
DRIVE_MODELS_PATH = '/content/drive/MyDrive/forex_models/'

# Crear directorio si no existe
os.makedirs(DRIVE_MODELS_PATH, exist_ok=True)
print(f"Modelos se guardarán en: {DRIVE_MODELS_PATH}")

# Ruta base donde están los archivos CSV en Google Drive
CSV_BASE_PATH = '/content/drive/MyDrive/'

# Lista de símbolos a procesar
symbols = ["USDCAD", "AUDUSD", "EURUSD", "GBPUSD", "USDCHF"]

# Parámetros
inp_history_size = 120

def get_csv_path(symbol):
    """Construye la ruta del CSV para un símbolo específico"""
    return f'{CSV_BASE_PATH}{symbol}_H1.csv'

# ============================================================================
# 5. FUNCIONES AUXILIARES
# ============================================================================

def split_sequence(sequence, n_steps):
    """Divide una secuencia en muestras para entrenamiento"""
    X, y = list(), list()
    for i in range(len(sequence)):
        end_ix = i + n_steps
        if end_ix > len(sequence) - 1:
            break
        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

def load_csv_data(csv_path, end_date=None, days_back=120):
    """
    Carga datos desde CSV y filtra por fecha si es necesario

    Parameters:
    - csv_path: Ruta al archivo CSV
    - end_date: Fecha final para filtrar (None = usar todos los datos)
    - days_back: Días hacia atrás desde end_date
    """
    # Leer CSV con delimitador de espacio/tabulador
    df = pd.read_csv(csv_path, delim_whitespace=True)

    # Renombrar columnas para eliminar los < >
    df.columns = df.columns.str.replace('<', '').str.replace('>', '')

    # Combinar DATE y TIME en una sola columna datetime
    df['DateTime'] = pd.to_datetime(df['DATE'] + ' ' + df['TIME'])
    df = df.sort_values('DateTime')

    # Filtrar por fecha si se especifica
    if end_date is not None:
        start_date = end_date - timedelta(days=days_back)
        df = df[(df['DateTime'] >= start_date) & (df['DateTime'] <= end_date)]

    # Verificar que tengamos la columna CLOSE
    if 'CLOSE' not in df.columns:
        raise ValueError("El CSV debe contener una columna 'CLOSE'")

    return df

def train_and_save_model(symbol, csv_path, end_date=None, model_suffix=""):
    """
    Entrena un modelo LSTM para predicción de precios

    Parameters:
    - symbol: Símbolo del par de divisas (e.g., "USDCAD")
    - csv_path: Ruta al archivo CSV con los datos
    - end_date: Fecha final para los datos de entrenamiento (None = usar todos)
    - model_suffix: Sufijo para el nombre del modelo (e.g., "backtesting")
    """
    # Crear nombre del modelo
    if model_suffix:
        model_name = f"model.{symbol}.H1.120.{model_suffix}.onnx"
    else:
        model_name = f"model.{symbol}.H1.120.onnx"

    print(f"\n{'='*60}")
    print(f"Procesando {symbol} - {model_suffix if model_suffix else 'Trading'}")
    if end_date:
        print(f"Fecha límite: {end_date}")
    print(f"{'='*60}\n")

    try:
        # Cargar datos del CSV
        df = load_csv_data(csv_path, end_date, days_back=inp_history_size * 2)

        if len(df) == 0:
            print(f"ERROR: No hay datos disponibles para {symbol}")
            return False

        print(f"Datos cargados: {len(df)} registros")

        # Obtener solo los precios de cierre
        data = df[['CLOSE']].values

        # Escalar datos
        scaler = MinMaxScaler(feature_range=(0, 1))
        scaled_data = scaler.fit_transform(data)

        # División 80/20 para entrenamiento y prueba
        training_size = int(len(scaled_data) * 0.80)
        print(f"Training_size: {training_size}")

        train_data_initial = scaled_data[0:training_size, :]
        test_data_initial = scaled_data[training_size:, :1]

        # Dividir en secuencias
        time_step = inp_history_size
        x_train, y_train = split_sequence(train_data_initial, time_step)
        x_test, y_test = split_sequence(test_data_initial, time_step)

        if len(x_train) == 0 or len(x_test) == 0:
            print(f"ERROR: No hay suficientes datos para crear secuencias")
            return False

        # Reshape para LSTM [samples, time steps, features]
        x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)
        x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)

        print(f"x_train shape: {x_train.shape}")
        print(f"x_test shape: {x_test.shape}")

        # Definir modelo
        model = Sequential()
        model.add(Conv1D(filters=256, kernel_size=2, activation='relu',
                        padding='same', input_shape=(inp_history_size, 1)))
        model.add(MaxPooling1D(pool_size=2))
        model.add(LSTM(100, return_sequences=True))
        model.add(Dropout(0.3))
        model.add(LSTM(100, return_sequences=False))
        model.add(Dropout(0.3))
        model.add(Dense(units=1, activation='sigmoid'))

        model.compile(optimizer='adam', loss='mse', metrics=[rmse()])

        # Early Stopping
        early_stop = EarlyStopping(
            monitor='val_loss',
            patience=20,
            restore_best_weights=True,
            verbose=1
        )

        # Entrenar modelo
        print(f"\nEntrenando modelo para {symbol}...")
        history = model.fit(
            x_train, y_train,
            epochs=300,
            validation_data=(x_test, y_test),
            batch_size=32,
            callbacks=[early_stop],
            verbose=1
        )

        # Evaluar modelo
        train_loss, train_rmse = model.evaluate(x_train, y_train, batch_size=32, verbose=0)
        print(f"\n✓ Train Loss: {train_loss:.4f} | Train RMSE: {train_rmse:.4f}")

        test_loss, test_rmse = model.evaluate(x_test, y_test, batch_size=32, verbose=0)
        print(f"✓ Test Loss: {test_loss:.4f} | Test RMSE: {test_rmse:.4f}")

        # Exportar a ONNX usando método directo
        temp_model_path = f"/content/temp_model_{symbol}_{model_suffix if model_suffix else 'trading'}"

        # Limpiar directorio temporal si existe
        if os.path.exists(temp_model_path):
            shutil.rmtree(temp_model_path)

        # Exportar modelo
        print("\nExportando modelo a formato SavedModel...")
        model.export(temp_model_path)

        # Convertir a ONNX usando tf2onnx directamente (método más robusto)
        output_path = os.path.join(DRIVE_MODELS_PATH, model_name)
        print(f"Convirtiendo a ONNX...")

        try:
            # Método 1: Usar tf2onnx.convert directamente desde Python
            import onnx
            from tf2onnx import tf_loader

            spec = (tf.TensorSpec((None, inp_history_size, 1), tf.float32, name="input"),)

            # Convertir el modelo
            model_proto, _ = tf2onnx.convert.from_keras(
                model,
                input_signature=spec,
                opset=13,
                output_path=output_path
            )

            print(f"✓ Modelo ONNX guardado exitosamente en: {output_path}")

        except Exception as e1:
            print(f"Método 1 falló: {str(e1)}")
            print("Intentando método alternativo...")

            try:
                # Método 2: Usar comando de shell con más opciones
                cmd = f'python -m tf2onnx.convert --saved-model "{temp_model_path}" --output "{output_path}" --opset 13 --verbose'
                result = subprocess.run(cmd, shell=True, capture_output=True, text=True)

                if result.returncode == 0 or os.path.exists(output_path):
                    print(f"✓ Modelo ONNX guardado exitosamente en: {output_path}")
                else:
                    print(f"✗ Error en conversión:")
                    print(f"stdout: {result.stdout}")
                    print(f"stderr: {result.stderr}")

                    # Intentar guardar el modelo en formato Keras nativo como respaldo
                    keras_path = output_path.replace('.onnx', '.keras')
                    model.save(keras_path)
                    print(f"⚠ Guardado en formato Keras alternativo: {keras_path}")

            except Exception as e2:
                print(f"✗ Método 2 también falló: {str(e2)}")

                # Guardar en formato Keras como último recurso
                keras_path = output_path.replace('.onnx', '.keras')
                model.save(keras_path)
                print(f"⚠ Guardado en formato Keras alternativo: {keras_path}")

        # Limpiar archivos temporales
        if os.path.exists(temp_model_path):
            shutil.rmtree(temp_model_path)

        print(f"\n✓ {symbol} - {model_suffix if model_suffix else 'Trading'} completado!\n")
        return True

    except Exception as e:
        print(f"\n✗ ERROR procesando {symbol}: {str(e)}\n")
        import traceback
        traceback.print_exc()
        return False

# ============================================================================
# 6. EJECUCIÓN PRINCIPAL
# ============================================================================

print(f"\n{'#'*60}")
print("# INICIO DEL ENTRENAMIENTO")
print(f"{'#'*60}\n")

# Procesar cada símbolo con su propio CSV
for symbol in symbols:
    print(f"\n{'#'*60}")
    print(f"# PROCESANDO {symbol}")
    print(f"{'#'*60}\n")
    
    # Obtener la ruta del CSV específico para este símbolo
    csv_path = get_csv_path(symbol)
    
    # Verificar que el CSV existe
    if not os.path.exists(csv_path):
        print(f"✗ ERROR: No se encontró el archivo CSV para {symbol}")
        print(f"  Ruta esperada: {csv_path}")
        print(f"  Saltando {symbol}...\n")
        continue
    
    print(f"✓ CSV encontrado: {csv_path}\n")

    # Modelo 1: Trading (todos los datos disponibles)
    print("→ Modelo de Trading (datos completos)")
    success_trading = train_and_save_model(symbol, csv_path, end_date=None, model_suffix="")

    # Modelo 2: Backtesting (excluyendo últimos 7 días)
    print("\n→ Modelo de Backtesting (hasta hace 7 días)")
    end_date_backtesting = datetime.now() - timedelta(days=7)
    success_backtesting = train_and_save_model(
        symbol, csv_path,
        end_date=end_date_backtesting,
        model_suffix="backtesting"
    )

    # Resumen
    if success_trading and success_backtesting:
        print(f"\n{'='*60}")
        print(f"✓✓ AMBOS MODELOS PARA {symbol} COMPLETADOS")
        print(f"{'='*60}\n")
    else:
        print(f"\n{'='*60}")
        print(f"✗ ALGUNOS MODELOS PARA {symbol} FALLARON")
        print(f"{'='*60}\n")

print(f"\n{'#'*60}")
print("# PROCESO COMPLETADO")
print(f"# Modelos guardados en: {DRIVE_MODELS_PATH}")
print(f"{'#'*60}")

# Listar modelos generados
print("\nModelos generados:")
for file in os.listdir(DRIVE_MODELS_PATH):
    if file.endswith('.onnx'):
        full_path = os.path.join(DRIVE_MODELS_PATH, file)
        size_mb = os.path.getsize(full_path) / (1024 * 1024)
        print(f"  ✓ {file} ({size_mb:.2f} MB)")
